# KPMG Virtual Internship Project - Data Quality Assessment and Recommendations

## Introduction
Welcome to the repository for the KPMG Virtual Internship Project - Data Quality Assessment and Recommendations. This project is a culmination of my efforts during the KPMG Virtual Internship, where I actively participated in assessing and improving the quality of the provided dataset from Sprocket Central Pty Ltd.

## Project Overview
- **Project Name:** Data Quality Assessment and Recommendations
- **Intern:** Shaik Thoukheer
- **Contact:** thoukheer.sk@gmail.com
- **LinkedIn:** [Shaik Thoukheer LinkedIn](https://www.linkedin.com/in/shaikthoukheer/)

## Project Description
The KPMG Virtual Internship offered a unique opportunity to delve into real-world data challenges. My role was to analyze the dataset from Sprocket Central Pty Ltd, identify data quality issues, and propose actionable recommendations for enhancing data accuracy and reliability.

## Key Contributions and Learnings
- **Data Cleaning and Consolidation:** Merged disparate data sheets using Google Sheets, employing advanced techniques to create a consolidated dataset. This process involved cleaning, formatting, and standardizing data for a holistic view.

- **Descriptive Statistics and Insights:** Utilized statistical methods in Google Sheets to generate insightful conclusions about the dataset. This included the identification of trends, patterns, and anomalies critical for decision-making.

- **Regression Analysis and Prediction:** Formulated regression equations for List Price and Standard Cost in Google Sheets, providing a predictive model for assessing the value of new customers. Applied these equations to derive meaningful insights and identify high-value customers.

- **Power BI Visualization:** Leveraged Power BI software to create interactive and visually compelling dashboards. These visualizations aided in presenting complex data relationships and trends with clarity.

## Data Quality Considerations
The project involved an exhaustive analysis of the dataset, leading to the identification of key data quality considerations. These considerations included handling empty cells, addressing unknown values, ensuring consistent formatting, and validating data integrity.

### Identified Data Quality Issues and Recommendations:
1. **Empty or Null Cells:** Proposed strategies for addressing missing values using Google Sheets to enhance data completeness.
2. **Unknown Values in Gender Column:** Provided suggestions for managing instances of "Unknown" in the gender column.
3. **Inconsistent Formatting:** Recommended standardization of formatting across sheets using Google Sheets for improved consistency.
4. **Data Validation:** Emphasized the importance of data validation in Google Sheets to ensure the correct format for each column.
5. **Symbol Usage:** Introduced "$" symbols for clarity in price values using Google Sheets for improved understanding.
6. **Deceased Indicator Interpretation:** Suggested confirming the interpretation of "n" in the "Deceased_Indicator" column for accurate analysis.
7. **Date Format Standardization:** Proposed changing date formats using Google Sheets for consistency and clarity.
8. **Selective Data Removal:** Advised considering selective removal of rows without job titles using Google Sheets to streamline the dataset.

## Equations and Predictions
The predictive modeling aspect of the project involved generating regression equations for List Price and Standard Cost using Google Sheets. These equations were then applied to new customer data, resulting in valuable insights and the identification of top customers.

### Regression Equations:
#### List Price ($):
\[ List Price = -0.558 + (4.580 * Gender) + (2.035 * Bike Purchases) + (43.829 * Current Age) - ... \]

#### Standard Cost ($):
\[ Standard Cost = -0.004 + (3.112 * Gender) + (-3.638 * Bike Purchases) + (14.939 * Current Age) - ... \]

### Predictions:
Applied the generated equations to new customer data, resulting in the identification of 526 top customers out of a thousand.

## Tools Used
- **Google Sheets:** Utilized for data cleaning, consolidation, and descriptive statistics.
- **Power BI:** Employed for creating interactive and visually appealing dashboards for data visualization.

## Project Structure
- **Data Cleaning Scripts:** In-depth Google Sheets formulas and scripts for data cleaning and consolidation.
- **Data Quality Report:** A comprehensive report on identified data quality issues and corresponding recommendations.
- **Equations and Predictions:** Regression equations and detailed steps for predictions.
- **Power BI Visualization:** Interactive Power BI dashboards for exploring consolidated and new customer data.

## Usage
1. **Clone the repository:** Begin by cloning this repository to your local machine.
2. **Explore Data Cleaning Scripts:** Dive into the 'Data Cleaning Scripts' directory to understand the intricate steps taken for data cleaning and consolidation.
3. **Read Data Quality Report:** Review the detailed 'Data Quality Report' for insights into identified issues and recommended solutions.
4. **Understand Equations and Predictions:** Explore the 'Equations and Predictions' directory for regression equations and steps taken for predictions.
5. **Visualize with Power BI:** Utilize Power BI files in the 'Power BI Visualization' directory to interactively explore consolidated and new customer data.

## Conclusion
This project was an immersive experience, providing hands-on exposure to data analysis, quality assessment, and predictive modeling. The insights gained are valuable for informed decision-making at Sprocket Central Pty Ltd.

Feel free to reach out for any questions, collaborations, or further discussions.

Happy exploring and coding!
